{
  "activation_function": "relu",
  "batch_size": 64,
  "epochs": 200,
  "frontend_data": true,
  "hidden_layer_neurons": 32,
  "hidden_layers": 3,
  "inputs_columns": [
    2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22,
    23, 24, 25, 26, 27, 28, 29, 30, 31
  ],
  "learning_rate": 0.01,
  "outputs": ["M", "B"],
  "outputs_column": "1",
  "plot_loss": true
}
