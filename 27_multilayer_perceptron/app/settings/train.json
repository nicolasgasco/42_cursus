{
  "activation_function": "relu",
  "hidden_layer_neurons": 24,
  "hidden_layers": 4,
  "inputs_columns": ["24", "29", "4", "8", "9"],
  "learning_rate": 0.01,
  "outputs": ["M", "B"],
  "outputs_column": "1"
}
